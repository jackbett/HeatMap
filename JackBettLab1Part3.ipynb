{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ubid = jackbett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jwong48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rtweet)\n",
    "\n",
    "create_token(\n",
    "  app = \"twitter_cse_487\",\n",
    "  consumer_key = \"AvBvCnIZwhoiWcE4T0IAuWWeM\",\n",
    "  consumer_secret = \"ZqgnlhOycqwrHuV9Cm7GCHpGlxobZgnQQyS0pcMHMtTldotDyl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(stringr)\n",
    "library(maps)\n",
    "library(sp)\n",
    "library(maps)\n",
    "library(maptools)\n",
    "library(rtweet)\n",
    "library(ggmap)\n",
    "library(gpclib)\n",
    "library(shiny)\n",
    "library(usmap)\n",
    "\n",
    "colorpallet = c(\"green4\",\"green2\",\"greenyellow\",\"yellowgreen\",\"yellow4\",\"gold3\",\"darkgoldenrod1\",\"darkorange\",\"red\",\"darkred\")\n",
    "\n",
    "grp = c(1,2,3,4,5,6,7,8,9,10)\n",
    "\n",
    "myDataFrame <- read.csv(\"StateDatabyWeekforMap_2018-19week40-4.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "states <-map_data(\"state\")\n",
    "\n",
    "heatData <- myDataFrame [865:918,4]\n",
    "regexp <- \"[[:digit:]]+\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "heatData <-str_extract(heatData, regexp)\n",
    "\n",
    "heatData<- as.numeric(heatData)\n",
    "\n",
    "\n",
    "df <- data.frame(myDataFrame$STATENAME,heatData)\n",
    "\n",
    "names(df) <- c(\"state\", \"heatData\")\n",
    "\n",
    "\n",
    "CDC_Heat <- plot_usmap(data =df,region = \"states\", values = \"heatData\",\n",
    "lines = \"black\")+scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\", name = \"Activity Level\") \n",
    "\n",
    "\n",
    "\n",
    "#first cdc heatmap\n",
    "\n",
    "# colorpallet = c(\"green4\",\"green2\",\"greenyellow\",\"yellowgreen\",\"yellow4\",\"gold3\",\"darkgoldenrod1\",\"darkorange\",\"red\",\"darkred\")\n",
    "\n",
    "# grp = c(1,2,3,4,5,6,7,8,9,10)\n",
    "\n",
    "# myDataFrame <- read.csv(\"StateDatabyWeekforMap_2018-19week40-4.csv\")\n",
    "\n",
    "# states <-map_data(\"state\")\n",
    "\n",
    "# heatData <- myDataFrame [865:918,4]\n",
    "# regexp <- \"[[:digit:]]+\"\n",
    "\n",
    "# heatData <-str_extract(heatData, regexp)\n",
    "\n",
    "# heatData<- as.numeric(heatData)\n",
    "\n",
    "# mapFrame <- data.frame(region = (tolower(myDataFrame[,1])), Level = c(heatData))\n",
    "\n",
    "# mapFinalFrame <- merge(states, mapFrame, sort = TRUE, (by = \"region\"))\n",
    "\n",
    "# mapFinalFrame <- mapFinalFrame[order(mapFinalFrame$Level),]\n",
    "\n",
    "# CDC_Heat<-ggplot(mapFinalFrame, aes(long, lat)) + geom_polygon(aes(group=group, fill= Level), col = \"black\") +\n",
    "# scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\") +coord_quickmap()\n",
    "\n",
    "\n",
    "#end first cdc heat map\n",
    "\n",
    "\n",
    "register_google(key = \"AIzaSyA276UW40OCxClxZeHV9CHag9Jnp3vJqJ8 \")\n",
    " ######################################################################################\n",
    "\n",
    "# Twitter Search\n",
    "rt <- search_tweets(\n",
    "  \"Flu Season\", geocode = lookup_coords(\"usa\"),include_rts = FALSE, n = 2000, lang = \"en\"\n",
    ")\n",
    "\n",
    "## create lat/lng variables using all available tweet and profile geo-location data\n",
    "rt <- lat_lng(rt)\n",
    "\n",
    "\n",
    "\n",
    "save_as_csv(rt, file_name = \"TwitterData.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "UserLocation <- data.frame(rt$screen_name, rt$lat, rt$lng)\n",
    "\n",
    "names(UserLocation) <- c(\"Name\", \"Latitude\", \"Longitude\")\n",
    "\n",
    "\n",
    "save_as_csv(UserLocation, file_name = \"TwitterUserLocation.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "# End Twitter Search, \n",
    "# User locations saved as screen name lat long\n",
    "# TwitterData Saved as all twitter data\n",
    "\n",
    " ######################################################################################\n",
    "\n",
    "\n",
    "MyData = read.csv(file = \"TwitterUserLocation.csv\")\n",
    "\n",
    "LatLong <- MyData[complete.cases(MyData),]\n",
    "\n",
    "#Function below converts to states\n",
    "\n",
    "latlong2state <- function(pointsDF) {\n",
    "    # Prepare SpatialPolygons object with one SpatialPolygon\n",
    "    # per state (plus DC, minus HI & AK)\n",
    "    states <- map('state', fill=TRUE, col=\"transparent\", plot=FALSE)\n",
    "    IDs <- sapply(strsplit(states$names, \":\"), function(x) x[1])\n",
    "    states_sp <- map2SpatialPolygons(states, IDs=IDs,\n",
    "                     proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Convert pointsDF to a SpatialPoints object \n",
    "    pointsSP <- SpatialPoints(pointsDF, \n",
    "                    proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Use 'over' to get _indices_ of the Polygons object containing each point \n",
    "    indices <- over(pointsSP, states_sp)\n",
    "\n",
    "    # Return the state names of the Polygons object containing each point\n",
    "    stateNames <- sapply(states_sp@polygons, function(x) x@ID)\n",
    "    stateNames[indices]\n",
    "}\n",
    "                         \n",
    "testPoints <- data.frame(x = LatLong$Longitude, y =LatLong$Latitude)\n",
    "                         \n",
    "# TwitterConvertedStates = latlong2state(testPoints)\n",
    "\n",
    "\n",
    "# coord <- data.frame(LatLong$Latitude,LatLong$Longitude, TwitterConvertedStates)  \n",
    "                       \n",
    "# names(coord) <- c(\"lat\",\"long\")\n",
    "                         \n",
    "# coord <- coord[complete.cases(coord), ]          \n",
    " \n",
    "# summary <- table(TwitterConvertedStates )                               \n",
    "                         \n",
    "# df <- as.data.frame(summary)\n",
    "                         \n",
    "                         \n",
    "# names(df) <- c(\"region\",\"occurence\")\n",
    "                       \n",
    "stateName <- data.frame(tolower(state.name))\n",
    "names(stateName) <- (\"region\")\n",
    "                        \n",
    "# df <-merge(df,stateName, by=\"region\", all = TRUE)\n",
    "\n",
    "                          \n",
    "# states <-map_data(\"state\")   \n",
    "TwitterConvertedStates = latlong2state(testPoints)\n",
    "\n",
    "\n",
    "coord <- data.frame(LatLong$Latitude,LatLong$Longitude)  \n",
    "                         \n",
    "                         \n",
    "names(coord) <- c(\"lat\",\"long\")\n",
    "                         \n",
    "coord <- coord[complete.cases(coord), ]  \n",
    "                                                                            \n",
    "summary <- table(TwitterConvertedStates)\n",
    "                                                                        \n",
    "df <- as.data.frame(summary)\n",
    "                         \n",
    "                         \n",
    "names(df) <- c(\"region\",\"occurence\")\n",
    "                    \n",
    "                         \n",
    "# stateName <- data.frame(tolower(state.name))\n",
    "# names(stateName) <- (\"region\")\n",
    "                                               \n",
    "\n",
    "\n",
    "df <-merge(df,stateName, by=\"region\", all = TRUE)\n",
    "                         \n",
    "colnames(df)[1] <-\"state\"\n",
    "\n",
    "    \n",
    "                         \n",
    "\n",
    "mapplot_Flu_Season <- plot_usmap(data =df,region = \"state\", values = \"occurence\",\n",
    "lines = \"black\")+scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\", name = \"Activity Level\") \n",
    "                                        \n",
    "# mapFinalFrame <- merge(states, df, sort = TRUE, by = \"region\", all = TRUE)  \n",
    "                        \n",
    "# mapplot_Flu_Season <-ggplot(mapFinalFrame, aes(long, lat), group = group) + geom_polygon(aes(group=group, fill= occurence), col = \"black\") + coord_quickmap() +\n",
    "# scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\",) +\n",
    "#                        geom_point(data=coord, aes(x=long, y=lat), color=\"blue\", size=.1)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#second twitter search\n",
    "#\n",
    "#\n",
    "#\n",
    "        \n",
    " ######################################################################################\n",
    "\n",
    "rt <- search_tweets(\n",
    "   geocode = lookup_coords(\"usa\"),include_rts = FALSE, n = 2000, lang = \"en\"\n",
    ")\n",
    "\n",
    "## create lat/lng variables using all available tweet and profile geo-location data\n",
    "rt <- lat_lng(rt)\n",
    "\n",
    "\n",
    "\n",
    "save_as_csv(rt, file_name = \"TwitterData2.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "UserLocation <- data.frame(rt$screen_name, rt$lat, rt$lng)\n",
    "\n",
    "names(UserLocation) <- c(\"Name\", \"Latitude\", \"Longitude\")\n",
    "\n",
    "\n",
    "save_as_csv(UserLocation, file_name = \"TwitterUserLocation2.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "\n",
    " ######################################################################################\n",
    "#User locations2 saved as screen name lat long\n",
    "#TwitterData2 Saved as all twitter data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MyData = read.csv(file = \"TwitterUserLocation2.csv\")\n",
    "\n",
    "\n",
    "LatLong <- MyData[complete.cases(MyData),]\n",
    "\n",
    "#Function below converts to states\n",
    "\n",
    "latlong2state <- function(pointsDF) {\n",
    "    # Prepare SpatialPolygons object with one SpatialPolygon\n",
    "    # per state (plus DC, minus HI & AK)\n",
    "    states <- map('state', fill=TRUE, col=\"transparent\", plot=FALSE)\n",
    "    IDs <- sapply(strsplit(states$names, \":\"), function(x) x[1])\n",
    "    states_sp <- map2SpatialPolygons(states, IDs=IDs,\n",
    "                     proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Convert pointsDF to a SpatialPoints object \n",
    "    pointsSP <- SpatialPoints(pointsDF, \n",
    "                    proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Use 'over' to get _indices_ of the Polygons object containing each point \n",
    "    indices <- over(pointsSP, states_sp)\n",
    "\n",
    "    # Return the state names of the Polygons object containing each point\n",
    "    stateNames <- sapply(states_sp@polygons, function(x) x@ID)\n",
    "    stateNames[indices]\n",
    "}\n",
    "                         \n",
    "\n",
    "\n",
    "testPoints <- data.frame(x = LatLong$Longitude, y =LatLong$Latitude)\n",
    "\n",
    "                         \n",
    "                    \n",
    "TwitterConvertedStates = latlong2state(testPoints)\n",
    "\n",
    "\n",
    "coord <- data.frame(LatLong$Latitude,LatLong$Longitude)  \n",
    "                         \n",
    "                         \n",
    "names(coord) <- c(\"lat\",\"long\")\n",
    "                         \n",
    "coord <- coord[complete.cases(coord), ]  \n",
    "                                                                            \n",
    "summary <- table(TwitterConvertedStates)\n",
    "                                                                        \n",
    "df <- as.data.frame(summary)\n",
    "                         \n",
    "                         \n",
    "names(df) <- c(\"region\",\"occurence\")\n",
    "                    \n",
    "                         \n",
    "# stateName <- data.frame(tolower(state.name))\n",
    "# names(stateName) <- (\"region\")\n",
    "                                               \n",
    "\n",
    "\n",
    "df <-merge(df,stateName, by=\"region\", all = TRUE)\n",
    "                         \n",
    "colnames(df)[1] <-\"state\"\n",
    "\n",
    "    \n",
    "                         \n",
    "\n",
    "mapplot_allwords <- plot_usmap(data =df,region = \"state\", values = \"occurence\",\n",
    "lines = \"black\")+scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\", name = \"Activity Level\") \n",
    " \n",
    " \n",
    "# mapplot_allwords <-ggplot(mapFinalFrame, aes(long, lat), group = group) + geom_polygon(aes(group=group, fill= occurence), col = \"black\")  +\n",
    "# scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\",) +  coord_equal()+\n",
    "#                        geom_point(data=coord, aes(x=long, y=lat), color=\"blue\", size=.1)\n",
    "                         \n",
    "         \n",
    "\n",
    "#\n",
    "                         #\n",
    "                         #\n",
    "                         #\n",
    "                         #end second twitter search\n",
    "                         #allwords\n",
    "                         #saved as\n",
    "                         #\n",
    "                         #\n",
    "                         \n",
    "\n",
    "ui <- pageWithSidebar(\n",
    "  \n",
    "  # App title ----\n",
    "  headerPanel(\"HeatMap\"),\n",
    "  \n",
    "  # Sidebar panel for inputs ----\n",
    "  sidebarPanel(\n",
    "  \n",
    "        # Input: Selector for variable to plot against mpg ----\n",
    "      selectInput(\"map\", \"Map Selection:\", \n",
    "                c(\"keyword: Flu Season\" = \"map1\",\n",
    "                  \"keyword: all\" = \"map2\"\n",
    "                  ))\n",
    "\n",
    "      # Input: Checkbox for whether outliers should be included ----\n",
    "      \n",
    "  \n",
    "  ),\n",
    "  \n",
    "  # Main panel for displaying outputs ----\n",
    "  mainPanel(\n",
    "\n",
    "    textOutput(\"text1\"),\n",
    "  plotOutput(\"plot1\"), \n",
    "    textOutput(\"text2\"),\n",
    "  plotOutput(\"plot2\")  ,\n",
    "     \n",
    "      \n",
    "   textOutput(\"text3\")   \n",
    "  )   \n",
    ")\n",
    "      \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "                         \n",
    " ######################################################################################\n",
    "                         \n",
    "                         \n",
    "# Twitter Search\n",
    "rt <- search_tweets(\n",
    "  \"Influenza\", geocode = lookup_coords(\"usa\"),include_rts = FALSE, n = 2000, lang = \"en\"\n",
    ")\n",
    "\n",
    "## create lat/lng variables using all available tweet and profile geo-location data\n",
    "rt <- lat_lng(rt)\n",
    "\n",
    "\n",
    "\n",
    "save_as_csv(rt, file_name = \"TwitterData3.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "\n",
    "UserLocation <- data.frame(rt$screen_name, rt$lat, rt$lng)\n",
    "\n",
    "names(UserLocation) <- c(\"Name\", \"Latitude\", \"Longitude\")\n",
    "\n",
    "\n",
    "save_as_csv(UserLocation, file_name = \"TwitterUserLocation3.csv\", prepend_ids = TRUE, na = \"\",\n",
    "  fileEncoding = \"UTF-8\")\n",
    "\n",
    "############################################################################################\n",
    "                         \n",
    "# End Twitter Search, \n",
    "# User locations saved as screen name lat long\n",
    "# TwitterData Saved as all twitter data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MyData = read.csv(file = \"TwitterUserLocation3.csv\")\n",
    "\n",
    "LatLong <- MyData[complete.cases(MyData),]\n",
    "\n",
    "#Function below converts to states\n",
    "\n",
    "latlong2state <- function(pointsDF) {\n",
    "    # Prepare SpatialPolygons object with one SpatialPolygon\n",
    "    # per state (plus DC, minus HI & AK)\n",
    "    states <- map('state', fill=TRUE, col=\"transparent\", plot=FALSE)\n",
    "    IDs <- sapply(strsplit(states$names, \":\"), function(x) x[1])\n",
    "    states_sp <- map2SpatialPolygons(states, IDs=IDs,\n",
    "                     proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Convert pointsDF to a SpatialPoints object \n",
    "    pointsSP <- SpatialPoints(pointsDF, \n",
    "                    proj4string=CRS(\"+proj=longlat +datum=WGS84\"))\n",
    "\n",
    "    # Use 'over' to get _indices_ of the Polygons object containing each point \n",
    "    indices <- over(pointsSP, states_sp)\n",
    "\n",
    "    # Return the state names of the Polygons object containing each point\n",
    "    stateNames <- sapply(states_sp@polygons, function(x) x@ID)\n",
    "    stateNames[indices]\n",
    "}\n",
    "                         \n",
    "testPoints <- data.frame(x = LatLong$Longitude, y =LatLong$Latitude)\n",
    "                         \n",
    "                     \n",
    "stateName <- data.frame(tolower(state.name))\n",
    "names(stateName) <- (\"region\")\n",
    "                        \n",
    " \n",
    "TwitterConvertedStates = latlong2state(testPoints)\n",
    "\n",
    "\n",
    "coord <- data.frame(LatLong$Latitude,LatLong$Longitude)  \n",
    "                         \n",
    "                         \n",
    "names(coord) <- c(\"lat\",\"long\")\n",
    "                         \n",
    "coord <- coord[complete.cases(coord), ]  \n",
    "                                                                            \n",
    "summary <- table(TwitterConvertedStates)\n",
    "                                                                        \n",
    "df <- as.data.frame(summary)\n",
    "                         \n",
    "                         \n",
    "names(df) <- c(\"region\",\"occurence\")\n",
    "                    \n",
    "                         \n",
    "# stateName <- data.frame(tolower(state.name))\n",
    "# names(stateName) <- (\"region\")\n",
    "                                               \n",
    "\n",
    "\n",
    "df <-merge(df,stateName, by=\"region\", all = TRUE)\n",
    "                         \n",
    "colnames(df)[1] <-\"state\"\n",
    "\n",
    "    \n",
    "                         \n",
    "\n",
    "mapplot_Influenza <- plot_usmap(data =df,region = \"state\", values = \"occurence\",\n",
    "lines = \"black\")+scale_fill_gradientn(colors = colorpallet, aesthetics = \"fill\", name = \"Activity Level\") \n",
    "     \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "ui <- pageWithSidebar(\n",
    "  \n",
    "  # App title ----\n",
    "  headerPanel(\"HeatMap\"),\n",
    "  \n",
    "  # Sidebar panel for inputs ----\n",
    "  sidebarPanel(\n",
    "  \n",
    "        # Input: Selector for variable to plot against mpg ----\n",
    "      selectInput(\"map\", \"Map Selection:\", \n",
    "                c(\"keyword: Flu Season\" = \"map1\",\n",
    "                  \"keyword: all\" = \"map2\", \"keyword: Influenza\" = \"map3\"\n",
    "                  ))\n",
    "\n",
    "      # Input: Checkbox for whether outliers should be included ----\n",
    "      \n",
    "  \n",
    "  ),\n",
    "  \n",
    "  # Main panel for displaying outputs ----\n",
    "  mainPanel(\n",
    "\n",
    "    textOutput(\"text1\"),\n",
    "  plotOutput(\"plot1\"), \n",
    "    textOutput(\"text2\"),\n",
    "  plotOutput(\"plot2\")  ,\n",
    "     \n",
    "      \n",
    "   textOutput(\"text3\")   \n",
    "  )   \n",
    ")\n",
    "                         \n",
    "                         \n",
    "                         \n",
    "server <- function(input, output){\n",
    "  \n",
    "output$text1 <- renderText({paste(\"This is my graph based on keyword.\"\n",
    "                                 )})\n",
    " output$text2 <- renderText({paste(\"This is my graph based on CDC Data Analysis\")})\n",
    "       \n",
    "  output$text3 <- renderText({paste(\"The key word Flu Season had less amount of tweets and geolocation compared to our CDC map.  Using all keywords shows much more geolcation usage.  Using the keyword influenza had similarities compared to our CDC map.\")})  \n",
    "\n",
    "output$plot2<- renderPlot({CDC_Heat})\n",
    "output$plot1 <- renderPlot({\n",
    "        \n",
    "\n",
    "    if (input$map == \"map1\" ) {\n",
    "        mapplot_Flu_Season\n",
    "     \n",
    "    }\n",
    "    else if (input$map == \"map2\") {\n",
    "   mapplot_allwords\n",
    "      \n",
    "    } else if (input$map == \"map3\"){\n",
    "        mapplot_Influenza\n",
    "    }\n",
    "    \n",
    "  })\n",
    "\n",
    "    \n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "shinyApp(ui, server)       #this runs the application and you will see result on localhost                         \n",
    "                         \n",
    "                       \n",
    "  \n",
    "                  \n",
    "                         \n",
    "                         \n",
    "                         \n",
    "    #this runs the application and you will see result on localhost                         \n",
    "                         \n",
    "                       \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
